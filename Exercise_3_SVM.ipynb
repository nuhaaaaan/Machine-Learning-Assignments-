{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuhaaaaan/Machine-Learning-Assignments-/blob/main/Exercise_3_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNuQqd2YmV03"
      },
      "source": [
        "<img src=\"../src/packt-banner.png\" alt=\"\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmADGEPKmV04"
      },
      "source": [
        "### Exercise 3: Build a SVM modle for Face Recognition Problem\n",
        "##### (25 points) --> your total will divided by 5 to get 5 points for this exercise.\n",
        "---\n",
        "\n",
        "We will use a very famous dataset, called Labelled Faces in the Wild, which\n",
        "consists of 1288 faces of famous people, and it is available at http://viswww.cs.umass.edu/lfw/lfw-funneled.tgz.\n",
        "\n",
        "However, note that it can be easily imported via scikit-learn from the datasets class.\n",
        "Each image consists of 1850 features: we could proceed by simply using each of them in the model.\n",
        "\n",
        "\n",
        "\n",
        "Fitting a SVM to non-linear data using the Kernel Trick produces non- linear decision boundaries.\n",
        "In particular, we seek to:\n",
        "* Build SVM model with radial basis function (RBF) kernel\n",
        "* Use a grid search cross-validation to explore ran- dom combinations of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR8Xn-XAmV05"
      },
      "source": [
        "### Step to do:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO4pnQdXmV05"
      },
      "source": [
        "1. Loading the dataf from sklearn.datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPWAbXW8mV05"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naK6Pwr-mV06"
      },
      "source": [
        "2. Since the data can be accessed from the sklearn.datasets module, you need to explore the dataset.\n",
        "    - (refer to the first 6 steps in Lab_1 could help you)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncdk2Q_cmV06"
      },
      "source": [
        "a- Print the field names (that is, the keys to the dictionary) (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maDYsJPqmV06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517035a1-d43b-4dcd-c16e-ef7e351325b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'images', 'target', 'target_names', 'DESCR'])\n"
          ]
        }
      ],
      "source": [
        "# What fields are in the dictionary?\n",
        "print(faces.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ld-9sJJmV07"
      },
      "source": [
        "b- Print the dataset description contained (2 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1r6mjnZmV07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9acfb99e-da56-417f-9b87-7c3c004eb268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _labeled_faces_in_the_wild_dataset:\n",
            "\n",
            "The Labeled Faces in the Wild face recognition dataset\n",
            "------------------------------------------------------\n",
            "\n",
            "This dataset is a collection of JPEG pictures of famous people collected\n",
            "over the internet, all details are available on the official website:\n",
            "\n",
            "http://vis-www.cs.umass.edu/lfw/\n",
            "\n",
            "Each picture is centered on a single face. The typical task is called\n",
            "Face Verification: given a pair of two pictures, a binary classifier\n",
            "must predict whether the two images are from the same person.\n",
            "\n",
            "An alternative task, Face Recognition or Face Identification is:\n",
            "given the picture of the face of an unknown person, identify the name\n",
            "of the person by referring to a gallery of previously seen pictures of\n",
            "identified persons.\n",
            "\n",
            "Both Face Verification and Face Recognition are tasks that are typically\n",
            "performed on the output of a model trained to perform Face Detection. The\n",
            "most popular model for Face Detection is called Viola-Jones and is\n",
            "implemented in the OpenCV library. The LFW faces were extracted by this\n",
            "face detector from various online websites.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "=================   =======================\n",
            "Classes                                5749\n",
            "Samples total                         13233\n",
            "Dimensionality                         5828\n",
            "Features            real, between 0 and 255\n",
            "=================   =======================\n",
            "\n",
            ".. dropdown:: Usage\n",
            "\n",
            "  ``scikit-learn`` provides two loaders that will automatically download,\n",
            "  cache, parse the metadata files, decode the jpeg and convert the\n",
            "  interesting slices into memmapped numpy arrays. This dataset size is more\n",
            "  than 200 MB. The first load typically takes more than a couple of minutes\n",
            "  to fully decode the relevant part of the JPEG files into numpy arrays. If\n",
            "  the dataset has  been loaded once, the following times the loading times\n",
            "  less than 200ms by using a memmapped version memoized on the disk in the\n",
            "  ``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\n",
            "\n",
            "  The first loader is used for the Face Identification task: a multi-class\n",
            "  classification task (hence supervised learning)::\n",
            "\n",
            "    >>> from sklearn.datasets import fetch_lfw_people\n",
            "    >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
            "\n",
            "    >>> for name in lfw_people.target_names:\n",
            "    ...     print(name)\n",
            "    ...\n",
            "    Ariel Sharon\n",
            "    Colin Powell\n",
            "    Donald Rumsfeld\n",
            "    George W Bush\n",
            "    Gerhard Schroeder\n",
            "    Hugo Chavez\n",
            "    Tony Blair\n",
            "\n",
            "  The default slice is a rectangular shape around the face, removing\n",
            "  most of the background::\n",
            "\n",
            "    >>> lfw_people.data.dtype\n",
            "    dtype('float32')\n",
            "\n",
            "    >>> lfw_people.data.shape\n",
            "    (1288, 1850)\n",
            "\n",
            "    >>> lfw_people.images.shape\n",
            "    (1288, 50, 37)\n",
            "\n",
            "  Each of the ``1140`` faces is assigned to a single person id in the ``target``\n",
            "  array::\n",
            "\n",
            "    >>> lfw_people.target.shape\n",
            "    (1288,)\n",
            "\n",
            "    >>> list(lfw_people.target[:10])\n",
            "    [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\n",
            "\n",
            "  The second loader is typically used for the face verification task: each sample\n",
            "  is a pair of two picture belonging or not to the same person::\n",
            "\n",
            "    >>> from sklearn.datasets import fetch_lfw_pairs\n",
            "    >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\n",
            "\n",
            "    >>> list(lfw_pairs_train.target_names)\n",
            "    ['Different persons', 'Same person']\n",
            "\n",
            "    >>> lfw_pairs_train.pairs.shape\n",
            "    (2200, 2, 62, 47)\n",
            "\n",
            "    >>> lfw_pairs_train.data.shape\n",
            "    (2200, 5828)\n",
            "\n",
            "    >>> lfw_pairs_train.target.shape\n",
            "    (2200,)\n",
            "\n",
            "  Both for the :func:`sklearn.datasets.fetch_lfw_people` and\n",
            "  :func:`sklearn.datasets.fetch_lfw_pairs` function it is\n",
            "  possible to get an additional dimension with the RGB color channels by\n",
            "  passing ``color=True``, in that case the shape will be\n",
            "  ``(2200, 2, 62, 47, 3)``.\n",
            "\n",
            "  The :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\n",
            "  3 subsets: the development ``train`` set, the development ``test`` set and\n",
            "  an evaluation ``10_folds`` set meant to compute performance metrics using a\n",
            "  10-folds cross validation scheme.\n",
            "\n",
            ".. rubric:: References\n",
            "\n",
            "* `Labeled Faces in the Wild: A Database for Studying Face Recognition\n",
            "  in Unconstrained Environments.\n",
            "  <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\n",
            "  Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\n",
            "  University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\n",
            "\n",
            "\n",
            ".. rubric:: Examples\n",
            "\n",
            "* :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "print(faces.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8WvKTFOmV07"
      },
      "source": [
        "3. Print the data, its shape, and the target names. ( 3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfL6no2FmV07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404ade96-8bd6-4525-c7b9-b60abac61042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.53464055 0.5254902  0.49673203 ... 0.00653595 0.00653595 0.00261438]\n",
            " [0.28627452 0.20784314 0.2522876  ... 0.96993464 0.9490196  0.9346406 ]\n",
            " [0.31895426 0.39215687 0.275817   ... 0.4261438  0.7908497  0.9555555 ]\n",
            " ...\n",
            " [0.11633987 0.11111111 0.10196079 ... 0.5686274  0.5803922  0.5542484 ]\n",
            " [0.19346406 0.21176471 0.2901961  ... 0.6862745  0.654902   0.5908497 ]\n",
            " [0.12287582 0.09803922 0.10980392 ... 0.12941177 0.1633987  0.29150328]]\n"
          ]
        }
      ],
      "source": [
        "# What does the data look like?\n",
        "print(faces.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qik3fdoQmV08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c29c26-b4af-41bc-f971-7d685b9e4ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1348, 2914)\n"
          ]
        }
      ],
      "source": [
        "# what is the shape of the data?\n",
        "print(faces.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aPc9uO-mV08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51312ad-0751-4e41-f253-7b5ae999cf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
            " 'Gerhard Schroeder' 'Hugo Chavez' 'Junichiro Koizumi' 'Tony Blair']\n"
          ]
        }
      ],
      "source": [
        "# What is the target names?\n",
        "print(faces.target_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUDpCWMCmV08"
      },
      "source": [
        "4. Divide the data into features (X) using the faces.data and target (y) using faces.target (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "06_1FUnMmV08"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "X =faces.data\n",
        "y =faces.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGzEfPYImV08"
      },
      "source": [
        "5. Splitting the data into training and testing sets. (2 point)\n",
        "\n",
        "We train the model with 70% of the samples and test with the remaining 30%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izd3Lq1wmV09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72bc9cb-b945-4932-cc44-3732f0326825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (943, 2914), Testing set size: (405, 2914)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print the sizes of our training and test set to verify if the splitting has occurred properly.\n",
        "print(f\"Training set size: {X_train.shape}, Testing set size: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQsoYQBmV09"
      },
      "source": [
        "6. Declare SVM model with kernel='rbf', class_weight='balanced' (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOID8jbUmV09"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# write your code here\n",
        "svm_model = SVC(kernel='rbf', class_weight='balanced')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB84KulSmV09"
      },
      "source": [
        "7. Use a grid search cross-validationwith 10 CV to explore random combinations of parameters. (3 points)\n",
        "    - we will adjust C, which controls the margin\n",
        "    - and Gamma (Î³), which controls the size of the radial basis function kernel, and determine the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL2TQsEQmV09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc316e2-e825-40d0-cddb-33343cfbe1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 50, 'gamma': 0.001}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [1, 5, 10, 50], 'gamma': [0.001, 0.0005, 0.01, 0.1]}\n",
        "\n",
        "# Grid search with 10-fold cross-validation\n",
        "grid_search = GridSearchCV(svm_model, param_grid, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by the grid search\n",
        "print(f'Best parameters: {grid_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo7MRALVmV0-"
      },
      "source": [
        "8. predict on the test set, using the best model from above step (best_estimator_) (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE6qWljxmV0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be9474a-0bca-41ab-c55e-44d711178595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on the test set: [3 4 3 6 6 1 3 3 3 3 3 3 4 3 3 1 7 2 3 2 7 7 5 5 0 3 6 7 3 3 0 6 3 3 2 3 2\n",
            " 3 3 2 3 3 7 1 3 3 0 2 1 2 7 3 4 6 7 3 7 1 7 0 4 2 7 2 5 4 7 3 4 3 1 3 4 1\n",
            " 3 4 0 4 3 3 1 3 1 0 7 2 3 2 7 0 1 1 2 3 3 1 7 3 3 1 3 7 1 4 3 3 0 3 7 3 3\n",
            " 1 0 1 3 1 3 2 3 4 7 7 5 4 3 3 3 3 2 2 3 3 0 3 4 3 4 1 2 1 7 6 5 3 3 1 0 3\n",
            " 4 4 3 2 7 1 7 1 3 7 1 4 6 1 2 3 2 3 1 7 2 2 1 7 3 3 1 1 1 3 3 1 0 0 1 1 7\n",
            " 1 1 5 3 4 3 3 7 5 6 3 7 7 3 2 2 3 2 3 3 6 3 3 1 7 3 6 1 3 3 1 1 7 6 3 1 3\n",
            " 1 7 7 2 7 7 5 7 1 3 3 2 3 4 7 2 3 1 3 7 7 1 4 3 1 1 5 4 2 3 4 1 1 1 2 2 3\n",
            " 7 3 7 3 7 3 1 3 1 3 1 1 1 3 3 1 4 4 3 1 4 1 0 0 3 2 0 2 5 1 3 3 6 2 1 3 6\n",
            " 3 1 3 5 1 1 1 3 3 3 3 3 3 5 0 1 1 3 3 1 1 7 1 1 6 3 1 1 5 7 3 2 1 3 1 3 3\n",
            " 7 3 1 0 3 6 3 7 3 3 0 5 3 1 6 3 0 1 1 0 1 0 4 1 3 2 2 3 1 4 4 2 3 1 3 1 1\n",
            " 3 1 3 2 3 2 7 1 7 3 1 2 6 4 1 7 3 3 3 3 3 2 3 3 5 1 1 2 5 6 2 5 7 3 3]\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print the predictions\n",
        "print(f'Predictions on the test set: {y_pred}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3A5gH2BmV0-"
      },
      "source": [
        "9. Model performances:\n",
        "Run the following code to print the model evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H51D6V2mV0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f454898-2bdf-408e-e3f3-db15b39ab2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel Sharon       0.59      0.76      0.67        17\n",
            "     Colin Powell       0.80      0.83      0.81        84\n",
            "  Donald Rumsfeld       0.67      0.81      0.73        36\n",
            "    George W Bush       0.90      0.86      0.88       146\n",
            "Gerhard Schroeder       0.69      0.71      0.70        28\n",
            "      Hugo Chavez       1.00      0.63      0.77        27\n",
            "Junichiro Koizumi       0.89      1.00      0.94        16\n",
            "       Tony Blair       0.82      0.78      0.80        51\n",
            "\n",
            "         accuracy                           0.81       405\n",
            "        macro avg       0.79      0.80      0.79       405\n",
            "     weighted avg       0.83      0.81      0.82       405\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "labels = list(faces.target_names)\n",
        "print(classification_report(y_test,y_pred,target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvhPBpEUmV0-"
      },
      "source": [
        "10. What do you observe about the model performances? (5 points)\n",
        "\n",
        "#### Write your answer here\n",
        "\n",
        "Observations on Model Performance:\n",
        "Noteworthy Accuracy:\n",
        "\n",
        "The model achieves an impressive overall accuracy of 81%, indicating strong performance in the face recognition task. This result reflects the effectiveness of using an SVM with the RBF kernel, which successfully differentiates between various individuals.\n",
        "Impact of Class Imbalance:\n",
        "\n",
        "It is evident that classes with a greater number of samples, such as George W. Bush (146 instances) and Colin Powell (84 instances), display superior performance metrics. The model learns to recognize these faces more reliably due to the larger volume of training data available. Conversely, classes like Ariel Sharon (17 instances) and Junichiro Koizumi (16 instances) show lower performance, suggesting that the model struggles to generalize well with limited data.\n",
        "Precision and Recall Balance:\n",
        "\n",
        "For several classes, precision and recall are relatively balanced. For example, George W. Bush exhibits a precision of 0.90 and a recall of 0.86, indicating that the model effectively identifies this class while minimizing false positives. However, for Hugo Chavez, although precision is perfect at 1.00, the recall is lower at 0.63, which means the model misses some actual instances while not misclassifying any.\n",
        "Robust F1-Scores:\n",
        "\n",
        "The F1-scores for most classes are commendable, especially for George W. Bush (0.88) and Colin Powell (0.81). These scores demonstrate a solid balance between precision and recall, crucial for evaluating classification models effectively.\n",
        "Generalization Across Classes:\n",
        "\n",
        "The macro average F1-score of 0.79 indicates a reasonable consistency across different classes, while the weighted average F1-score of 0.82 shows that the performance is boosted by classes with more data. This suggests that while the model performs well overall, improvements can be made in handling classes with fewer instances.\n",
        "Conclusion:\n",
        "In summary, the model exhibits strong performance, particularly for classes with a higher number of samples. Nonetheless, it faces challenges with less represented classes, where precision and recall could be better optimized. Implementing strategies to address class imbalance, such as oversampling smaller classes or employing class-weighted SVMs, could enhance the model's effectiveness and improve its generalization across all categories.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6B-4lQ-V7jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "interpreter": {
      "hash": "9be90a182e443121e767cfcadea61fa0eeced8ec62a9bd8ae9861f6c1d839655"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('venvml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}